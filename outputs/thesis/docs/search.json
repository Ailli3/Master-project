[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ANU Thesis",
    "section": "",
    "text": "Preface\nThis thesis template is intended for honours, masters or PhD students at the Australian National University (ANU) who wish to write their thesis using the Quarto document format. It is highly recommended for students who code using Python, R or Julia and have many computational or analysis results in their thesis.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#benefits",
    "href": "index.html#benefits",
    "title": "ANU Thesis",
    "section": "Benefits",
    "text": "Benefits\nThe benefits of using Quarto document include:\n\nIt allows you to write your thesis in a simple markup language called Markdown. This means that you can focus on writing your thesis without having to worry about formatting.\nThe document can be output to a variety of formats including PDF, HTML, Word, and LaTeX.\nCode can be easily embedded in the document and executed. This means that you can include the results of your analysis in your thesis without having to manually copy and paste them. This is a good reproducible and scientific practice.\nYou can easily integrate with aspects of GitHub (edit, reporting an issue, etc).\n\nThe above outlined benefits can also be considered as best practice. Version controlling and collaborative writing (via Git and GitHub) are important in managing multiple versions of your thesis and in collaborating with your supervisory team. Embedding code in your thesis is a good practice in reproducible research. Making your thesis in HTML format can allow for interactive web elements to be embedded while PDF format can be for general distribution and printing.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "ANU Thesis",
    "section": "Getting started",
    "text": "Getting started\nThere are several systems that you are expected to know to use this template. These include:\n\nMarkdown syntax for writing\nQuarto or R Markdown syntax (note that these works for Python or Julia too) for embedding code\n(Optional) Git and GitHub for hosting",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#frequently-asked-questions",
    "href": "index.html#frequently-asked-questions",
    "title": "ANU Thesis",
    "section": "Frequently asked questions",
    "text": "Frequently asked questions\n\nWhat about Overleaf?\nANU has a professional account for Overleaf, which is great for those that use LaTeX regularly. Unfortunately, there is no equivalent system with track changes in Quarto. You can output the tex file from Quarto document and use this in Overleaf. The changes made in this tex document however has to be manually transferred back to the Quarto document. If your main output is mainly mathematical and you have little to no code outputs, Overleaf is probably a better choice.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "disclaimer.html",
    "href": "disclaimer.html",
    "title": "Disclaimer",
    "section": "",
    "text": "This thesis is composed of my original work, and contains no material previously published or written by another person except where due reference has been made in the text. I have clearly stated the contribution by others to jointly-authored works that I have included in my thesis.\nI have clearly stated the contribution of others to my thesis as a whole, including statistical assistance, study design, data analysis, significant technical procedures, professional editorial advice, financial support and any other original research work used or reported in my thesis. The content of my thesis is the result of work I have carried out since the commencement of my higher degree by research candidature and does not include a substantial part of work that has been submitted to qualify for the award of any other degree or diploma in any university or other tertiary institution. I have clearly stated which parts of my thesis, if any, have been submitted to qualify for another award.\n\nYour Name\n2024-01-24\n\n\nPublications\nAccepted or in-press publication in this thesis.\nSubmitted manuscripts included in this thesis.\nOther publications during candidature.",
    "crumbs": [
      "Disclaimer"
    ]
  },
  {
    "objectID": "acknowledgements.html",
    "href": "acknowledgements.html",
    "title": "Acknowledgements",
    "section": "",
    "text": "I would like to express my sincere gratitude to my dog, Chuckles, for eating my research notes multiple times. If it wasn’t for you, I would have finished this thesis earlier.",
    "crumbs": [
      "Acknowledgements"
    ]
  },
  {
    "objectID": "chapter1.html",
    "href": "chapter1.html",
    "title": "1  Introduction",
    "section": "",
    "text": "Reproducible research is an essential paradigm that promotes the idea that scientific investigations should be transparent, verifiable, and accessible to others. In an era where the scientific community faces concerns about the replicability of research findings, adopting reproducible research practices becomes imperative.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "chapter2.html",
    "href": "chapter2.html",
    "title": "2  Method",
    "section": "",
    "text": "This report underscores the transformative impact of reproducible research on the scientific landscape, promoting a commitment to openness and accountability for the benefit of the entire research community.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Method</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Allaire, JJ. 2023. Quarto: R Interface to ’Quarto’ Markdown\nPublishing System. https://CRAN.R-project.org/package=quarto.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "tools.html",
    "href": "tools.html",
    "title": "Appendix A — Tools",
    "section": "",
    "text": "This thesis was written using Quarto 1.4.545 (Allaire 2023) and the following system and R packages:\n\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.3.1 (2023-06-16)\n os       macOS Sonoma 14.2.1\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Australia/Sydney\n date     2024-01-24\n pandoc   3.1.1 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n cli           3.6.2   2023-12-11 [1] CRAN (R 4.3.1)\n digest        0.6.33  2023-07-07 [1] CRAN (R 4.3.0)\n evaluate      0.23    2023-11-01 [1] CRAN (R 4.3.1)\n fastmap       1.1.1   2023-02-24 [1] CRAN (R 4.3.0)\n htmltools     0.5.7   2023-11-03 [1] CRAN (R 4.3.1)\n htmlwidgets   1.6.4   2023-12-06 [1] CRAN (R 4.3.1)\n jsonlite      1.8.8   2023-12-04 [1] CRAN (R 4.3.1)\n knitr         1.45    2023-10-30 [1] CRAN (R 4.3.1)\n later         1.3.2   2023-12-06 [1] CRAN (R 4.3.1)\n processx      3.8.3   2023-12-10 [1] CRAN (R 4.3.1)\n ps            1.7.5   2023-04-18 [1] CRAN (R 4.3.0)\n quarto        1.3     2023-09-19 [1] CRAN (R 4.3.1)\n Rcpp          1.0.12  2024-01-09 [1] CRAN (R 4.3.1)\n rlang         1.1.3   2024-01-10 [1] CRAN (R 4.3.1)\n rmarkdown     2.25    2023-09-18 [1] CRAN (R 4.3.1)\n rstudioapi    0.15.0  2023-07-07 [1] CRAN (R 4.3.0)\n sessioninfo   1.2.2   2021-12-06 [1] CRAN (R 4.3.0)\n xfun          0.41    2023-11-01 [1] CRAN (R 4.3.1)\n yaml          2.3.8   2023-12-11 [1] CRAN (R 4.3.1)\n\n [1] /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────\n\n\n\n\n\n\nAllaire, JJ. 2023. Quarto: R Interface to ’Quarto’ Markdown Publishing System. https://CRAN.R-project.org/package=quarto.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Tools</span>"
    ]
  },
  {
    "objectID": "background.html",
    "href": "background.html",
    "title": "2  Background",
    "section": "",
    "text": "2.1 Linear model\nSuppose we have a linear model,\n\\boldsymbol{y}=\\mathbf{X}\\boldsymbol{\\tau} + \\boldsymbol{\\epsilon} \\tag{2.1} where \\boldsymbol{y} is n\\times 1 vector of n observations, \\boldsymbol{\\tau} is a t\\times 1 vector of fixed effects, \\boldsymbol{\\epsilon} is the n\\times 1 vector for error, and \\mathbf{X} is a design matrix has size n\\times t. We assume that \\boldsymbol{\\epsilon} \\sim N(\\boldsymbol{0}, \\sigma^2\\textbf{I}_{n}) and hence \\boldsymbol{y} \\sim N(\\mathbf{X}\\boldsymbol{\\tau}, \\sigma^2\\mathbf{I}_n).\nThe log-likelihood of Equation 2.1 is then given as:\n\\log\\ell(\\boldsymbol{\\tau};\\boldsymbol{y}) = -\\frac{n}{2}\\log(2\\pi)-n\\log(\\sigma)-\\frac{1}{2\\sigma^2}(\\boldsymbol{y}-\\textbf{X}\\boldsymbol{\\tau})^\\top(\\boldsymbol{y}-\\textbf{X}\\boldsymbol{\\tau}).\n The (i,j)-th entry of the Fisher information matrix is defined as\nI_{ij}(\\boldsymbol{\\tau})=-\\mathbb{E}\\left(\\frac{\\partial^2}{\\partial\\tau_i\\partial\\tau_j}\\log\\ell(\\boldsymbol{\\tau};\\boldsymbol{y})\\right)\n where \\tau_i is the i-th entry of \\boldsymbol{\\tau}.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Background</span>"
    ]
  },
  {
    "objectID": "background.html#linear-model",
    "href": "background.html#linear-model",
    "title": "2  Background",
    "section": "",
    "text": "Lemma 2.1 The Fisher information matrix of Equation 2.1 is given as \n\\mathbf{C} = -\\mathbb{E}\\left(\\frac{\\partial^2}{\\partial\\boldsymbol{\\tau}\\partial\\boldsymbol{\\tau}^\\top}\\log\\ell(\\boldsymbol{\\tau};\\boldsymbol{y})\\right)=\\frac{1}{\\sigma^2}\\textbf{X}^\\top\\textbf{X}\n\n\n\nProof. The second derivative of the log-likelihood function \\log\\ell(\\boldsymbol{\\tau};\\boldsymbol{y}) is the Hessian matrix. We have \n\\frac{\\partial}{\\partial\\boldsymbol{\\tau}}\\log\\ell(\\boldsymbol{\\tau};\\boldsymbol{y})=\\frac{1}{\\sigma^2}\\textbf{X}^\\top(\\boldsymbol{y}-\\textbf{X}\\boldsymbol{\\tau})\n and for second derivative is \n\\frac{\\partial^2}{\\partial\\boldsymbol{\\tau}\\partial\\boldsymbol{\\tau}^\\top}\\log\\ell(\\boldsymbol{\\tau};\\boldsymbol{y})==-\\frac{1}{\\sigma^2}\\textbf{X}^\\top\\textbf{X}\n And in linear model assumption we have \\boldsymbol{y} \\sim N(\\mathbf{X}\\boldsymbol{\\tau}, \\sigma^2\\mathbf{I}_n) and the Fisher information matrix is unbiased because, in the expectation calculation process, we do not involve the randomness of \\boldsymbol{y}. The Fisher information matrix is actually determined by the design matrix \\textbf{X} and the error variance \\sigma^2. Hence \n\\mathbb{E}\\left(\\frac{\\partial^2}{\\partial\\boldsymbol{\\tau}\\partial\\boldsymbol{\\tau}^\\top}\\log\\ell(\\boldsymbol{\\tau};\\boldsymbol{y})\\right)=-\\frac{1}{\\sigma^2}\\textbf{X}^\\top\\textbf{X} = -\\mathbf{C}\n So \\mathbf{C} = \\frac{1}{\\sigma^2}\\textbf{X}^\\top\\textbf{X}\n\n\nLemma 2.2 The variance of the fixed effects for Equation 2.1 is equivalent to the inverse of the Fisher information matrix, i.e. var(\\hat{\\boldsymbol{\\tau}})=\\sigma^2(\\textbf{X}^\\top\\textbf{X})^{-1} = \\mathbf{C}^{-1}.\n\n\nProof. We know that the MLE of \\boldsymbol{\\tau} in a linear model is \\hat{\\boldsymbol{\\tau}}=(\\textbf{X}^\\top\\textbf{X})^{-1}\\textbf{X}^\\top\\boldsymbol{y}. By assumption we have \\boldsymbol{y} \\sim N(\\mathbf{X}\\boldsymbol{\\tau}, \\sigma^2\\mathbf{I}_n). So \\hat{\\boldsymbol{\\tau}}\\sim N(\\boldsymbol{\\tau},\\sigma^2(\\textbf{X}^\\top\\textbf{X})^{-1}).So we have var(\\hat{\\boldsymbol{\\tau}}) = \\sigma^2(\\textbf{X}^\\top\\textbf{X})^{-1}, which is exactly the inverse of Fisher information matrix \\mathbf{C}^{-1}.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Background</span>"
    ]
  },
  {
    "objectID": "background.html#a-criterion",
    "href": "background.html#a-criterion",
    "title": "2  Background",
    "section": "3.1 A-criterion",
    "text": "3.1 A-criterion\nWe first start with a simple example, that is, we consider treatment factors \\boldsymbol{\\tau} are fixed, to elucidate the influence of A-criterion.\nFrom David Butler (2013), we conduct a maximum log likelihood by following objective function: \n\\log f_Y(\\boldsymbol{y}|\\boldsymbol{u};\\boldsymbol{\\tau},\\textbf{R})+\\log f_u(\\boldsymbol{u};\\textbf{G})\n basing on assumption, we have \\boldsymbol{y}=\\textbf{X}\\boldsymbol{\\tau}+\\textbf{Z}\\boldsymbol{u}+\\boldsymbol{\\epsilon}\\sim N(\\textbf{X}\\boldsymbol{\\tau},\\textbf{R}+\\textbf{ZGZ}^\\top). So for objective function, we can write out the distributions\n\n\\boldsymbol{y}|\\boldsymbol{u};\\boldsymbol{\\tau},\\textbf{R}\\sim N(\\textbf{X}\\boldsymbol{\\tau}+\\textbf{Z}\\boldsymbol{u},\\textbf{R}) \\\\\n\\boldsymbol{u}\\sim N(\\boldsymbol{0},\\textbf{G})\n\n\nLemma 3.1 So log of joint density is given as\n\\begin{align*}\n\\mathscr{L}&=\\log f_Y(\\boldsymbol{y}|\\boldsymbol{u};\\boldsymbol{\\tau},\\textbf{R})+\\log f_u(\\boldsymbol{u};\\textbf{G})\\\\\n&=-\\frac{1}{2}\\left(\\log|\\textbf{R}|+\\log|\\textbf{G}|+(\\boldsymbol{y}-\\textbf{X}\\boldsymbol{\\tau}-\\textbf{Z}\\boldsymbol{u})^\\top \\mathbf{R}^{-1}(\\boldsymbol{y}-\\textbf{X}\\boldsymbol{\\tau}-\\textbf{Z}\\boldsymbol{u})+\\boldsymbol{u}^\\top\\textbf{G}^{-1}\\boldsymbol{u}\\right)\n\\end{align*}\n\n\nProof. Where is the proof?\n\nWe determine that \\frac{\\partial\\mathscr{L}}{\\partial\\boldsymbol{\\tau}}=\\frac{\\partial\\mathscr{L}}{\\partial\\boldsymbol{u}}=\\boldsymbol{0}, and write the equation into a matrix form \n\\begin{bmatrix}\n\\textbf{X}^\\top\\textbf{R}^{-1}\\textbf{X} & \\textbf{X}^\\top\\textbf{R}^{-1}\\textbf{Z}\\\\\n\\textbf{Z}^\\top\\textbf{R}^{-1}\\textbf{X} & \\textbf{Z}^\\top\\textbf{R}^{-1}\\textbf{Z}+ \\textbf{G}^{-1}\n\\end{bmatrix}\n\\begin{bmatrix}\n\\hat{\\boldsymbol{\\tau}}\\\\\n\\hat{\\boldsymbol{u}}\n\\end{bmatrix}=\n\\begin{bmatrix}\n\\textbf{X}^\\top\\textbf{R}^{-1}\\boldsymbol{y}\\\\\n\\textbf{Z}^\\top\\textbf{R}^{-1}\\boldsymbol{y}\n\\end{bmatrix}\n\nLet \n\\textbf{C}=\n\\begin{bmatrix}\n\\textbf{X}^\\top\\textbf{R}^{-1}\\textbf{X} & \\textbf{X}^\\top\\textbf{R}^{-1}\\textbf{Z}\\\\\n\\textbf{Z}^\\top\\textbf{R}^{-1}\\textbf{X} & \\textbf{Z}^\\top\\textbf{R}^{-1}\\textbf{Z}+ \\textbf{G}^{-1}\n\\end{bmatrix}\n\\quad\n\\hat{\\boldsymbol{\\beta}}=\\begin{bmatrix}\n\\hat{\\boldsymbol{\\tau}}\\\\\n\\hat{\\boldsymbol{u}}\n\\end{bmatrix}\n\\quad\n\\textbf{W}=\\begin{bmatrix}\\textbf{X} &\\textbf{Z}\\end{bmatrix}\n\nRobinson (1991) shows that \n\\hat{\\boldsymbol{\\beta}}=\\begin{bmatrix}\n\\hat{\\boldsymbol{\\tau}}\\\\\n\\hat{\\boldsymbol{u}}\n\\end{bmatrix}\\sim\nN(\\begin{bmatrix}\n\\hat{\\boldsymbol{\\tau}}\\\\\n\\hat{\\boldsymbol{u}}\n\\end{bmatrix}, \\textbf{C}^{-1})\n\nWe can rewrite the equation in a standard form \\textbf{C}\\hat\\beta=\\textbf{W}^\\top\\textbf{R}^{-1}y. So \\textbf{C} is the Fisher information matrix for this linear mixed model. As we mentioned above, we are interesting in examine fixed effect part \\boldsymbol{\\tau}. For the properties of variance-covariance matrix, matrix \\textbf{C} can be written as \n\\textbf{C}=\n\\begin{bmatrix}\n\\textbf{C}_{11} & \\textbf{C}_{12}\\\\\n\\textbf{C}_{21} & \\textbf{C}_{22}\n\\end{bmatrix}\n \\textbf{C}_{11}^{-1} is a t \\times t matrix and variance-covariance matrix for treatment factors. We can caluclate \\textbf{C}_{11} by writing out standard form for \\boldsymbol{\\tau} and cancelling \\boldsymbol{u}.We have \n\\boldsymbol{X}^\\top\\textbf{R}^{-1}\\textbf{X}\\boldsymbol{\\tau}+\\textbf{X}^\\top\\textbf{R}^{-1}\\textbf{Z}(\\textbf{Z}^\\top\\textbf{R}^{-1}\\textbf{Z}+\\textbf{G}^{-1})\\textbf{Z}^\\top\\textbf{R}^{-1}y=\\textbf{X}^\\top\\textbf{R}^{-1}y\\\\\n \n\\Rightarrow \\textbf{X}^\\top[\\textbf{R}^{-1}-\\textbf{R}^{-1}\\textbf{Z}(\\textbf{Z}^\\top\\textbf{R}^{-1}\\textbf{Z}+\\textbf{G}^{-1})^{-1}\\textbf{Z}^\\top\\textbf{R}^{-1}]\\textbf{X}\\boldsymbol{\\tau}=\\textbf{X}^\\top[\\textbf{R}^{-1}-\\textbf{R}^{-1}\\textbf{Z}(\\textbf{Z}^\\top\\textbf{R}^{-1}\\textbf{Z}+\\textbf{G}^{-1})^{-1}\\textbf{Z}^\\top\\textbf{R}^{-1}]y\\\\\n \n\\Rightarrow \\textbf{X}^\\top\\textbf{P}\\textbf{X}\\boldsymbol{\\tau}=\\textbf{X}^\\top\\textbf{P}y\n where \\textbf{P}=\\textbf{R}^{-1}-\\textbf{R}^{-1}\\textbf{Z}(\\textbf{Z}^\\top\\textbf{R}^{-1}\\textbf{Z}+\\textbf{G}^{-1})^{-1}\\textbf{Z}^\\top\\textbf{R}^{-1}, let \\textbf{C}_{11}=\\textbf{X}^\\top\\textbf{P}\\textbf{X} then we have the standard form for \\hat{\\boldsymbol{\\tau}}, which is \\textbf{C}_{11}\\boldsymbol{\\tau}=\\textbf{X}^\\top\\textbf{P}y, and \\textbf{C}_{11} is the corresponding Fisher information matrix.\nSo we have \\boldsymbol{\\tau}-\\hat{\\boldsymbol{\\tau}}\\sim N(0,\\textbf{C}_{11}^{-1}).To examine a specific form of \\boldsymbol{\\tau}, we do linear transform on \\boldsymbol{\\tau}: \\hat{\\boldsymbol{\\pi}}=\\textbf{D}\\hat{\\boldsymbol{\\tau}}, where \\textbf{D} is some transform matrix, so we have \\textbf{D}(\\boldsymbol{\\tau}-\\hat{\\boldsymbol{\\tau}})=\\boldsymbol{\\pi}-\\hat{\\boldsymbol{\\pi}}\\sim N(0,\\textbf{D}\\textbf{C}_{11}^{-}\\textbf{D}^\\top). We denote \\boldsymbol{\\Lambda}=\\textbf{D}\\textbf{C}_{11}^{-}\\textbf{D}^\\top.\nA-criterion is the mean of predicted error variance of the parameter. i.e.  \n\\mathscr{A}=\\frac{1}{n_{\\pi}(n_{\\pi}-1)}\\sum_{i}\\sum_{j&lt;i} predicted\\quad error\\quad variance\\quad of\\quad(\\hat\\pi_i-\\hat\\pi_j)\n where n_{\\pi} is the row number of vector \\pi.For error variance part, we have \n\\sum_{i}\\sum_{j&lt;i} predicted\\quad error\\quad variance\\quad of\\quad(\\hat\\pi_i-\\hat\\pi_j)=\\sum_{i}\\sum_{j&lt;i}var(\\hat\\pi_i-\\hat\\pi_j)=\\sum_{i}\\sum_{j&lt;i}[var(\\hat\\pi_i)+var(\\hat\\pi_j)-2cov(\\hat\\pi_i,\\hat\\pi_j)]\n from virance-covirance matrix \\boldsymbol{\\Lambda}, we can rewrite the sum part as n_{\\pi}tr(\\boldsymbol{\\Lambda})-\\mathbb{1}_{n_{\\pi}}^\\top\\boldsymbol{\\Lambda}\\mathbb{1}_{n_{\\pi}}.So we have \n\\mathscr{A}=\\frac{1}{n_{\\pi}(n_{\\pi}-1)}[n_{\\pi}tr(\\boldsymbol{\\Lambda})-\\mathbb{1}_{n_{\\pi}}^\\top\\boldsymbol{\\Lambda}\\mathbb{1}_{n_{\\pi}}]\n same result from DG Butler, Smith, and Cullis (2013)\nDerivation above indicate that \\mathscr{A}\\propto tr(\\boldsymbol{\\Lambda}), A-criterion as the mean of predicted error variance of the parameter, we prefer it as small as possible to obtain a accurate result from experiment, which means the trace of virance-covirance matrix \\boldsymbol{\\Lambda} should be as small as possible. And this is our goal on optimal experimental design.\n\n\n\n\nButler, David. 2013. “On the Optimal Design of Experiments Under the Linear Mixed Model.”\n\n\nButler, DG, AB Smith, and BR Cullis. 2013. “On Model Based Design of Comparative Experiments.” preparation.\n\n\nRobinson, George K. 1991. “That BLUP Is a Good Thing: The Estimation of Random Effects.” Statistical Science, 15–32.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Background</span>"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "In the field of experimental design, efficient methods are crucial for ensuring accurate and reliable results. One such method is the row-column design, controlling variability in experiments involving two factors, typically arranged in rows and columns. The row-column design can be considered as an extension of the Latin square design with more flexibility, allowing for different numbers of rows, columns, and treatments. This flexibility makes row-column designs applicable to a wider range of experimental settings.\nTo offer a row-column design that gives a precise estimation of treatment effects, one way is to seek the optimal value of some statistic criteria, for example, A-criteria(links to sections), minimizing the variance of elementary treatment contrasts. Using linear mixed model and assuming fixed treatment effects and random blocking effect, Butler (2013) has show the relation between optimizing design and minimizing the value of A-criteria, and show some possible algorithms to search optimal design in feasible set. These algorithms mainly focus on comparing the arrangements of different treatments, that is, doing permutations, and calculating their A values, optimizing design by iterations.\nHowever, some undesired cluster of replications or some treatment may occur when algorithm are doing permutations along rows and columns. Piepho, Michel, and Williams (2018) found that such clustering is considered undesirable by experimenters who worry that irregular environmental gradients might negatively impact multiple replications of the same treatment, potentially leading to biased treatment effect estimates. Williams emphasis that there is a need to design a strategy to avoid clustering and achieve even distribution of treatment replications among the experimental field. Two properties of design are introduced. Even distribution of treatment replications, abbreviated as ED, and neighbor balance, abbreviated as NB. A good ED ensures every replications of a treatment are widely spread in experimental field, and NB helps to avoid replications of the some treatment cluster together repeatedly. Williams introduce a scoring system to analysis ED and NB for a specific design, and introduce a algorithm to optimize ED, NB and some average efficiency factor can be represented by a specific statistic criteria.(maybe saying some improvement is needed)\nWe offer an optimization strategy for a design problem, which we can improving ED and NB during optimizing statistic criteria for a design, and avoid unwanted clustering and self-adjacency on the resulting design.In this algorithm, we use A-criteria to evaluate the efficiency of a design. Before the algorithm, we randomly generate a design as an initial design, and calculate the A-criteria as initial value. We update design by selecting a better among its neighbors. The neighbors are pair-wise permutations of a design. Typically, we select a neighbor from all pairwise permutations of a design for iteration, but this does not ensure ED and NB. To ensure ED and NB during optimization, we need to add some constraints when generating the pairwise permutations.(maybe explain what is the constraints) By filtering design with bad ED and NB, we then optimize the statistic criteria of the design.\n(sections in the thesis)\n\n\n\n\nButler, David. 2013. “On the Optimal Design of Experiments Under the Linear Mixed Model.”\n\n\nPiepho, Hans-Peter, Volker Michel, and Emlyn Williams. 2018. “Neighbor Balance and Evenness of Distribution of Treatment Replications in Row-Column Designs.” Biometrical Journal 60 (6): 1172–89.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  }
]